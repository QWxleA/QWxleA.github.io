shadow$provide.module$node_modules$codemirror$mode$tornado$tornado=function(global,require,module,exports){(function(mod){"object"==typeof exports&&"object"==typeof module?mod(require("module$node_modules$codemirror$lib$codemirror"),require("module$node_modules$codemirror$mode$htmlmixed$htmlmixed"),require("module$node_modules$codemirror$addon$mode$overlay")):"function"==typeof define&&define.amd?define(["../../lib/codemirror","../htmlmixed/htmlmixed","../../addon/mode/overlay"],mod):mod(CodeMirror)})(function(CodeMirror){CodeMirror.defineMode("tornado:inner",
function(){function tokenBase(stream,state){stream.eatWhile(/[^\{]/);var ch=stream.next();if("{"==ch&&(ch=stream.eat(/\{|%|#/)))return state.tokenize=inTag(ch),"tag"}function inTag(close){"{"==close&&(close="}");return function(stream,state){return stream.next()==close&&stream.eat("}")?(state.tokenize=tokenBase,"tag"):stream.match(keywords)?"keyword":"#"==close?"comment":"string"}}var keywords="and as assert autoescape block break class comment context continue datetime def del elif else end escape except exec extends false finally for from global if import in include is json_encode lambda length linkify load module none not or pass print put raise raw return self set squeeze super true try url_escape while with without xhtml_escape yield".split(" ");
keywords=new RegExp("^(("+keywords.join(")|(")+"))\\b");return{startState:function(){return{tokenize:tokenBase}},token:function(stream,state){return state.tokenize(stream,state)}}});CodeMirror.defineMode("tornado",function(config){var htmlBase=CodeMirror.getMode(config,"text/html");config=CodeMirror.getMode(config,"tornado:inner");return CodeMirror.overlayMode(htmlBase,config)});CodeMirror.defineMIME("text/x-tornado","tornado")})}
//# sourceMappingURL=module$node_modules$codemirror$mode$tornado$tornado.js.map
